---
category: command
excerpt: ""
title: blackbox
tags: [Black-box]
date: '2016-09-17'
sidebar:
  nav: "commands"
---

[blackbox](/command/blackbox) can be used to apply essentially arbitrary operators on [sdpvar](/command/sdpvar) objects.

[blackbox](/command/blackbox) is only available in the develop branch. A previuos version is [sdpfun](/command/sdpfun)
{: .notice--info}

## Syntax


````matlab
y = blackbox(x,f)
y = blackbox(x,f,'derivative',df,'convex','increasing',...)
````

## Examples

Nonlinear functions are supported through the [callback nonlinear operator framework](/tutorial/nonlinearoperatorscallback). Most functions (exponentials, logarithms, trigonometrics, etc.) are available from start, but the user can use [blackbox](/command/blackbox) as a last resort to define other (elementwise) functions, without going through the hassle of creating completely defined operators. It can also be a trick to circumvent symblic handling of very large complex operations which involves many functions but a small number of decision variables.

### Basic use

The following example shows how we can use a nonlinear solver to find a local optimizer to a small trigonometric problem. Of course, all involved operators here are already supported natively, so the use of [blackbox](/command/blackbox) is only for illustration. The important difference is that YALMIP never sees cosine, sine or quadratics in the first approach. It will only be given iterates of \\(x\\) from the solver, and then call the black-box function and return the function value to the solver. In the standard second model, YALMIP will explicitly work with the computational tree of the expression.

````matlab
sdpvar x
y = blackbox(x,@(x)(sin(cos(x^2))))
optimize([1 <= x <= 2],y)

optimize([1 <= x <= 2],sin(cos(x^2)))
````

If you have the function implemented in a file, you can use a function handle or a file name.

````matlab
y = blackbox(x,@myfile)
````

Vectorized elementwise functions are supported too

````matlab
x = sdpvar(2,3);
y = blackbox(x,@(x)(sin(cos(x.^2))))
optimize([1 <= x <= 2],sum(sum(y)))
````

In the following example, we have a small number of decision variables, but the introduction of the exponential operator on a large linear function will introduce a large amount of symbolic expressions and auxilliary variables which will cause unnecessary performance loss.

````matlab
A = randn(1000,2);b = randn(1000,1);
y = exp(A*[3;3] + b);

% Nonlinear least squares, slow version where YALMIP introduces intermediate variables
x = sdpvar(2,1);
e = exp(A*x + b) - y;
optimize([],e'*e);

% Define operator which computes fit, YALMIP and solver only sees \\(x\\).
J = @(x)(sum((exp(A*x + b)-y).^2));
f = blackbox(x,J);
optimize([],f)
````

### Supplying derivatives

As an example of a more complicated scenario, let us maximize \\(\int_0^a (x^2-x^3)dx\\) with respect to the integration limit \\(a \geq 0\\). To implement the integral, we use the MATLAB command integral which takes a function handle and the two limits, which in our case means one of the limit arguments is a decision variable.

````matlab
f = @(a)(integral(@(x) x.^2-x.^3,0,a))
sdpvar a
Area = blackbox(a,f);
optimize(a>=0,-Area)
````

In our examples above, the solver will use numerical differentiation, but if we have a gradient available, we can supply it. Calculus to the rescue!

````matlab
f = @(a)(integral(@(x) x.^2-x.^3,0,a))
sdpvar a
df = @(a)(a^2-a^3);
Area = blackbox(a,f,'derivative',df);
optimize(a>=0,-Area)
````

### Advanced use in global optimization


## Comments

The command also supports \\R^n \rightarrow R\\) functions, but this is not recommended when using [BMIBNB](solver/bmibnb) as no convex hull generation is performed.
